"""
å°ç±³äº’è”æœåŠ¡ App Store è¯„è®ºçˆ¬å–ä¸åˆ†æå·¥å…·
ä¸»ç¨‹åºå…¥å£
"""
import argparse
import os
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config.settings import APP_NAME, COUNTRY, DATA_DIR
from src.scraper import AppStoreScraper
from src.parser import ReviewParser
from src.classifier import ReviewClassifier


def print_separator(char="=", length=70):
    """æ‰“å°åˆ†éš”çº¿"""
    print(char * length)


def print_rating_bar(count: int, total: int, bar_length: int = 20) -> str:
    """ç”Ÿæˆè¯„åˆ†æ¡å½¢å›¾"""
    if total == 0:
        return ""
    percentage = count / total
    filled = int(bar_length * percentage)
    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
    return f"{bar} {count:3d} ({percentage * 100:5.1f}%)"


def print_analysis_report(analysis: dict, platform: str):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    print_separator("=")
    print(f"ğŸ“± {platform} å¹³å°åˆ†ææŠ¥å‘Š")
    print_separator("=")
    
    summary = analysis.get("summary", {})
    total = summary.get("total_reviews", 0)
    avg_rating = summary.get("average_rating", 0)
    rating_dist = summary.get("rating_distribution", {})
    
    # è¯„åˆ†åˆ†å¸ƒ
    print(f"\nâ­ è¯„åˆ†åˆ†å¸ƒ (å…± {total} æ¡è¯„è®ºï¼Œå¹³å‡ {avg_rating:.2f} æ˜Ÿ)")
    print("-" * 50)
    for star in range(5, 0, -1):
        count = rating_dist.get(star, 0)
        bar = print_rating_bar(count, total)
        print(f"  {star} æ˜Ÿ: {bar}")
    
    # æŒ‰è¯„åˆ†åˆ†ç±»
    print(f"\nğŸ“Š è¯„åˆ†åˆ†ç±»ç»Ÿè®¡")
    print("-" * 50)
    by_rating = analysis.get("by_rating", {})
    for category, data in by_rating.items():
        count = data.get("count", 0)
        pct = data.get("percentage", 0)
        print(f"  {category}: {count} æ¡ ({pct}%)")
    
    # æŒ‰å…³é”®è¯åˆ†ç±»
    print(f"\nğŸ“ é—®é¢˜ç±»å‹åˆ†ç±»")
    print("-" * 50)
    by_keywords = analysis.get("by_keywords", {})
    for category, data in sorted(by_keywords.items(), key=lambda x: x[1].get("count", 0), reverse=True):
        count = data.get("count", 0)
        if count > 0:
            pct = data.get("percentage", 0)
            print(f"  {category}: {count} æ¡ ({pct}%)")
    
    # æŒ‰æƒ…æ„Ÿåˆ†ç±»
    print(f"\nğŸ˜Š æƒ…æ„Ÿåˆ†æ")
    print("-" * 50)
    by_sentiment = analysis.get("by_sentiment", {})
    sentiment_emoji = {"æ­£é¢": "ğŸ˜Š", "ä¸­æ€§": "ğŸ˜", "è´Ÿé¢": "ğŸ˜"}
    for sentiment, data in by_sentiment.items():
        count = data.get("count", 0)
        pct = data.get("percentage", 0)
        emoji = sentiment_emoji.get(sentiment, "")
        print(f"  {emoji} {sentiment}: {count} æ¡ ({pct}%)")
    
    # é«˜é¢‘è¯ç»Ÿè®¡
    print(f"\nğŸ”¤ é«˜é¢‘è¯ Top 15")
    print("-" * 50)
    word_freq = analysis.get("word_frequency", [])[:15]
    for i, (word, count) in enumerate(word_freq, 1):
        bar = "â–“" * min(count // 2, 20)
        print(f"  {i:2d}. {word:<8} {bar} ({count})")
    
    # TF-IDF å…³é”®è¯
    print(f"\nğŸ”‘ TF-IDF å…³é”®è¯ Top 10")
    print("-" * 50)
    keywords_tfidf = analysis.get("keywords_tfidf", [])[:10]
    for i, (word, weight) in enumerate(keywords_tfidf, 1):
        bar = "â–“" * int(weight * 30)
        print(f"  {i:2d}. {word:<8} {bar} ({weight:.3f})")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å°ç±³äº’è”æœåŠ¡ App Store è¯„è®ºçˆ¬å–ä¸åˆ†æå·¥å…·")
    parser.add_argument("--app", type=str, default=APP_NAME, help="åº”ç”¨åç§°")
    parser.add_argument("--country", type=str, default=COUNTRY, help="å›½å®¶/åœ°åŒºä»£ç ")
    parser.add_argument("--pages", type=int, default=10, help="æœ€å¤§çˆ¬å–é¡µæ•° (æœ€å¤š10)")
    args = parser.parse_args()
    
    print_separator()
    print("ğŸ App Store è¯„è®ºçˆ¬å–ä¸åˆ†æå·¥å…·")
    print_separator()
    print(f"ğŸ“± ç›®æ ‡åº”ç”¨: {args.app}")
    print(f"ğŸŒ åœ°åŒº: ä¸­å›½å¤§é™† ({args.country})")
    print(f"ğŸ“„ æœ€å¤§é¡µæ•°: {args.pages}")
    print(f"ğŸ“… è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print_separator()
    
    # åˆå§‹åŒ–ç»„ä»¶
    scraper = AppStoreScraper(country=args.country)
    review_parser = ReviewParser()
    classifier = ReviewClassifier()
    
    try:
        # Step 1: çˆ¬å–è¯„è®º
        print("\nğŸ“¥ å¼€å§‹çˆ¬å–è¯„è®º...")
        scrape_results = scraper.scrape_all_platforms(args.app)
        
        if not scrape_results:
            print("âŒ æœªè·å–åˆ°ä»»ä½•è¯„è®ºæ•°æ®")
            return
        
        # Step 2: è§£æè¯„è®º
        print("\nğŸ“ è§£æè¯„è®ºæ•°æ®...")
        all_reviews = review_parser.parse_all_reviews(scrape_results)
        print(f"  å…±è§£æ {len(all_reviews)} æ¡è¯„è®º")
        
        # Step 3: ä¿å­˜åŸå§‹æ•°æ®
        print("\nğŸ’¾ ä¿å­˜æ•°æ®...")
        csv_path = review_parser.save_to_csv(all_reviews)
        print(f"  CSV æ–‡ä»¶: {csv_path}")
        
        json_path = review_parser.save_to_json(all_reviews)
        print(f"  JSON æ–‡ä»¶: {json_path}")
        
        app_info_path = review_parser.save_app_info(scrape_results)
        print(f"  åº”ç”¨ä¿¡æ¯: {app_info_path}")
        
        # Step 4: åˆ†æè¯„è®º
        print("\nğŸ“Š å¼€å§‹åˆ†æè¯„è®º...")
        
        # æŒ‰å¹³å°åˆ†åˆ«åˆ†æ
        all_analysis = {}
        for platform, data in scrape_results.items():
            platform_reviews = [r for r in all_reviews if r.get("platform") == data.get("platform")]
            if platform_reviews:
                analysis = classifier.analyze_all(platform_reviews)
                all_analysis[platform] = analysis
                print_analysis_report(analysis, platform)
        
        # æ•´ä½“åˆ†æ
        if len(scrape_results) > 1:
            print("\n")
            overall_analysis = classifier.analyze_all(all_reviews)
            all_analysis["overall"] = overall_analysis
            print_analysis_report(overall_analysis, "å…¨å¹³å°æ±‡æ€»")
        
        # Step 5: ä¿å­˜åˆ†æç»“æœ
        analysis_path = classifier.save_analysis(all_analysis)
        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {analysis_path}")
        
        # æ‰“å°ç¤ºä¾‹è¯„è®º
        print_separator()
        print("\nğŸ’¬ è¯„è®ºç¤ºä¾‹")
        print_separator()
        
        for platform, data in scrape_results.items():
            print(f"\nğŸ“± {platform}:")
            reviews = data.get("reviews", [])[:3]
            for i, review in enumerate(reviews, 1):
                stars = "â­" * review.get("rating", 0)
                print(f"\n  [{i}] {stars}")
                print(f"      æ ‡é¢˜: {review.get('title', 'N/A')}")
                content = review.get("content", "")
                if len(content) > 100:
                    content = content[:100] + "..."
                print(f"      å†…å®¹: {content}")
                print(f"      ç‰ˆæœ¬: {review.get('version', 'N/A')}")
        
        print_separator()
        print("âœ… çˆ¬å–ä¸åˆ†æå®Œæˆ!")
        print_separator()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        scraper.close()


if __name__ == "__main__":
    main()
